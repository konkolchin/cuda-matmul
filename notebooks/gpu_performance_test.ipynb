{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Matrix Multiplication Performance Test\n",
    "\n",
    "This notebook is designed to run in Google Colab to test GPU performance of our CUDA matrix multiplication implementation. It focuses on two matrix sizes to keep the testing compact and efficient.\n",
    "\n",
    "**Note:** This notebook is intended for Linux environments (Google Colab) only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install numpy pytest matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup repository directory\n",
    "import os\n",
    "# Go to /content directory\n",
    "%cd /content\n",
    "# Remove any existing cuda-matmul directory\n",
    "!rm -rf cuda-matmul\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/konkolchin/cuda-matmul.git\n",
    "%cd cuda-matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package in development mode\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cuda_ops\n",
    "import cuda_runtime\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_gpu():\n",
    "    \"\"\"Check CUDA availability and print device info.\"\"\"\n",
    "    try:\n",
    "        device_count = cuda_runtime.cudaGetDeviceCount()\n",
    "        logger.info(f\"Found {device_count} CUDA device(s)\")\n",
    "        \n",
    "        if device_count > 0:\n",
    "            props = cuda_runtime.cudaGetDeviceProperties(0)\n",
    "            logger.info(f\"Device 0: {props.name.decode() if hasattr(props, 'name') else 'Unknown'}\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.warning(\"No CUDA devices found\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error checking CUDA availability: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "has_gpu = check_gpu()\n",
    "if not has_gpu:\n",
    "    raise RuntimeError(\"No GPU available. Please ensure you're running this notebook in Google Colab with GPU runtime.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_performance_test(m, n, k, block_sizes=[16, 32]):\n",
    "    \"\"\"Run performance test for given matrix dimensions.\"\"\"\n",
    "    logger.info(f\"\\nTesting {m}x{n} matrices...\")\n",
    "    \n",
    "    # Generate test matrices\n",
    "    a = np.random.rand(m, k).astype(np.float32)\n",
    "    b = np.random.rand(k, n).astype(np.float32)\n",
    "    \n",
    "    # Warm-up runs\n",
    "    for _ in range(2):\n",
    "        cuda_ops.matrix_multiply(a, b, use_gpu=False)\n",
    "        for block_size in block_sizes:\n",
    "            cuda_ops.matrix_multiply(a, b, use_gpu=True, block_size=block_size)\n",
    "    \n",
    "    # CPU timing\n",
    "    start = time.time()\n",
    "    for _ in range(3):\n",
    "        cuda_ops.matrix_multiply(a, b, use_gpu=False)\n",
    "    cpu_time = (time.time() - start) / 3\n",
    "    \n",
    "    # GPU timing\n",
    "    gpu_times = []\n",
    "    speedups = []\n",
    "    \n",
    "    for block_size in block_sizes:\n",
    "        start = time.time()\n",
    "        for _ in range(3):\n",
    "            cuda_ops.matrix_multiply(a, b, use_gpu=True, block_size=block_size)\n",
    "        gpu_time = (time.time() - start) / 3\n",
    "        gpu_times.append(gpu_time)\n",
    "        speedups.append(cpu_time / gpu_time)\n",
    "    \n",
    "    return {\n",
    "        'size': f\"{m}x{n}\",\n",
    "        'cpu_time': cpu_time,\n",
    "        'gpu_times': gpu_times,\n",
    "        'speedups': speedups\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run performance tests with two matrix sizes\n",
    "sizes = [(1024, 1024), (2048, 2048)]  # Two representative sizes\n",
    "block_sizes = [16, 32]\n",
    "\n",
    "# Print header\n",
    "header = \"Matrix Size\\tCPU Time (s)\\tGPU 16x16 (s)\\tGPU 32x32 (s)\\tSpeedup 16x16\\tSpeedup 32x32\"\n",
    "print(\"\\nPerformance Test Results:\")\n",
    "print(header)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Run tests and collect results\n",
    "results = []\n",
    "for m, n in sizes:\n",
    "    k = m  # Square matrices\n",
    "    result = run_performance_test(m, n, k, block_sizes)\n",
    "    results.append(result)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{result['size']}\\t\\t{result['cpu_time']:.4f}\\t\\t\"\n",
    "          f\"{result['gpu_times'][0]:.4f}\\t\\t{result['gpu_times'][1]:.4f}\\t\\t\"\n",
    "          f\"{result['speedups'][0]:.2f}x\\t\\t{result['speedups'][1]:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(results):\n",
    "    sizes = [r['size'] for r in results]\n",
    "    cpu_times = [r['cpu_time'] for r in results]\n",
    "    gpu_times_16 = [r['gpu_times'][0] for r in results]\n",
    "    gpu_times_32 = [r['gpu_times'][1] for r in results]\n",
    "    \n",
    "    x = range(len(sizes))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar([i - width for i in x], cpu_times, width, label='CPU')\n",
    "    plt.bar(x, gpu_times_16, width, label='GPU (16x16)')\n",
    "    plt.bar([i + width for i in x], gpu_times_32, width, label='GPU (32x32)')\n",
    "    \n",
    "    plt.xlabel('Matrix Size')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.title('Matrix Multiplication Performance Comparison')\n",
    "    plt.xticks(x, sizes)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
